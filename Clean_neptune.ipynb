{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785b7d8c",
   "metadata": {},
   "source": [
    "## A more clean notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4805c6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiencing connection interruptions. Will try to reestablish communication with Neptune. Internal exception was: RequestsFutureAdapterConnectionError\n",
      "Experiencing connection interruptions. Will try to reestablish communication with Neptune. Internal exception was: RequestsFutureAdapterConnectionError\n",
      "Experiencing connection interruptions. Reestablishing communication with Neptune.\n",
      "Experiencing connection interruptions. Reestablishing communication with Neptune.\n",
      "Experiencing connection interruptions. Reestablishing communication with Neptune.\n",
      "Experiencing connection interruptions. Reestablishing communication with Neptune.\n",
      "Experiencing connection interruptions. Reestablishing communication with Neptune.\n",
      "Experiencing connection interruptions. Reestablishing communication with Neptune.\n",
      "Experiencing connection interruptions. Reestablishing communication with Neptune.\n",
      "Experiencing connection interruptions. Reestablishing communication with Neptune.\n",
      "Experiencing connection interruptions. Reestablishing communication with Neptune.\n",
      "Experiencing connection interruptions. Reestablishing communication with Neptune.\n"
     ]
    }
   ],
   "source": [
    "# Load all packages\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np\n",
    "     \n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from torch import nn\n",
    "import neptune.new as neptune\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef0f39",
   "metadata": {},
   "source": [
    "### Start the neptune run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9608fd0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/Facemask-project/Facemask/e/FAC-24\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "# Get the APi key, from outside the git folder.\n",
    "file = open(\"../API-key.txt\", \"r\")\n",
    "key = file.readlines()\n",
    "\n",
    "run = neptune.init(\n",
    "    project=\"Facemask-project/Facemask\",\n",
    "    api_token=key[0])\n",
    "\n",
    "# Choose the device:\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c16ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['namespace/Run_name'] = \"Test Run\"\n",
    "run['sys/tags'].add(['size_50', \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31f3c32",
   "metadata": {},
   "source": [
    "## Create the dataloader\n",
    "\n",
    "This Dataloader is using read_image, which is not the fastest way to load files. It might be better to use the cv2 library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f62aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "#Create the data loader. This data\n",
    "class DataLoader():\n",
    "    def __init__(self, img_dir, img_dir2, transform = None, target_transform=None, transforms = None,\n",
    "                 random_perspective = None, flip = None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_dir2 = img_dir2\n",
    "        self.transform = transform\n",
    "        self.transforms = transforms\n",
    "        self.fileNames = os.listdir(img_dir)\n",
    "        self.random_perspective = random_perspective\n",
    "        self.flip = flip\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.img_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.fileNames[idx].rsplit(\"t-mask-\", 1 )[1]\n",
    "        img_path = os.path.join(self.img_dir, self.fileNames[idx])\n",
    "        img_path2 = os.path.join(self.img_dir2, label)\n",
    "        image = read_image(img_path)\n",
    "        target_image = read_image(img_path2)\n",
    "        image = image.clone().detach().float()\n",
    "        target_image = target_image.clone().detach().float()\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "            target_image = self.transforms(target_image)\n",
    "            \n",
    "        if self.random_perspective:\n",
    "            if random.uniform(0,1) > 0.5:\n",
    "                scale = random.uniform(0,0.3)\n",
    "                startpoints, endpoints = transforms.RandomPerspective().get_params(50,50, distortion_scale=scale)\n",
    "                image = torchvision.transforms.functional.perspective(image, startpoints, endpoints)\n",
    "                target_image  = torchvision.transforms.functional.perspective(target_image, startpoints, endpoints)\n",
    "        \n",
    "        return image, target_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0c565d",
   "metadata": {},
   "source": [
    "## Set up the dataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4c113b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose batch_size:\n",
    "batch_size = 25\n",
    "\n",
    "#create transformer with mean = 0 and std = 1.\n",
    "transformer=transforms.Compose([ transforms.Normalize((0, 0, 0), (1, 1, 1))])\n",
    "\n",
    "#Create the dataset with the dataloader:\n",
    "dataset = DataLoader(\"Data_small/50_with_mask\", \"Data_small/50_without_mask\",\n",
    "                     transform = transformer,\n",
    "                    random_perspective = None,\n",
    "                    flip = False) \n",
    "\n",
    "# split the dataset into test and train set.\n",
    "test_size = int(0.2 * len(dataset))\n",
    "train_size = len(dataset) - test_size\n",
    "test_train_split = [test_size, train_size]\n",
    "testdata, traindata = torch.utils.data.random_split(dataset = dataset, lengths = test_train_split)\n",
    "\n",
    "# Set up dataloader and the test\n",
    "trainloader = torch.utils.data.DataLoader(traindata, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=0,\n",
    "                                          pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(testdata, \n",
    "                                          batch_size=1, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=0,\n",
    "                                          pin_memory=True)\n",
    "dataiter = iter(trainloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a93ce",
   "metadata": {},
   "source": [
    "## Set up the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "415858f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 3, 50, 50])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with auto encoder:\n",
    "\n",
    "import torch.nn.functional as F\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "           \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(4608,4000)\n",
    "        self.linear2 = nn.Linear(4000,750)\n",
    "        self.linear3 = nn.Linear(750,300)\n",
    "\n",
    "\n",
    "        \n",
    "        self.unflatten = nn.Unflatten(dim =1, unflattened_size = (3,10,10))\n",
    "        #Encoder\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.conv11 = nn.Conv2d(8, 16, 3, padding=1) \n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 7, padding=3)\n",
    "        self.conv4 = nn.Conv2d(64, 50, 5, padding=2)\n",
    "        self.conv5 = nn.Conv2d(50, 40, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(40, 32, 3, padding=1)\n",
    "       \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        #Decoder\n",
    "        self.t_conv1 = nn.ConvTranspose2d(3, 8, 3, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(8, 16, 3, stride=1)\n",
    "        self.t_conv3 = nn.ConvTranspose2d(16, 8 , 3, stride=1)\n",
    "        self.t_conv4 = nn.ConvTranspose2d(8, 3, 2, stride=2)\n",
    "\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv6(x))\n",
    "        return x\n",
    "    \n",
    "    def flatlayer(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x):\n",
    "        x = self.unflatten(x)\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        x = F.relu(self.t_conv2(x))\n",
    "        x = F.relu(self.t_conv3(x))\n",
    "        x = F.relu(self.t_conv4(x))\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encode(x)\n",
    "        x = self.flatlayer(x)\n",
    "        x = self.decode(x)      \n",
    "        return x\n",
    "\n",
    "\n",
    "#Instantiate the model\n",
    "model = ConvAutoencoder()\n",
    "\n",
    "#Send the model to the device\n",
    "model.to(device)\n",
    "# check the model output is the correct size\n",
    "model(dataiter.next()[0].to(device)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edc89799",
   "metadata": {},
   "outputs": [],
   "source": [
    "run[\"test\"] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddd3fbb",
   "metadata": {},
   "source": [
    "### Set up the neptune parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf7a3f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "#Loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "#Optimizer\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def update_params():\n",
    "    run[\"parameters\"] = {\"lr\": learning_rate,\n",
    "                         \"optim\": str(optimizer).split(\" \")[0],\n",
    "                         \"loss_function\" : str(criterion),\n",
    "                         \"Batch_size\": batch_size\n",
    "                        }\n",
    "update_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e7ea2",
   "metadata": {},
   "source": [
    "### Create the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb10431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epochs\n",
    "def train(model, n_epochs = 10, criterion = criterion, optimizer = optimizer, trainloader = trainloader):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # monitor training loss\n",
    "        train_loss = 0.0\n",
    "\n",
    "        #Training\n",
    "        for data in trainloader:\n",
    "            mask_image, image = data\n",
    "            mask_image , image = mask_image.to(device), image.to(device)\n",
    "            image = image.clone().detach().float()\n",
    "            mask_image = mask_image.clone().detach().float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(mask_image)\n",
    "            loss = criterion(outputs, image)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if (epoch % 1 == 0):\n",
    "            train_loss += loss.item()\n",
    "            print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "            run[\"train/loss\"].log(train_loss)\n",
    "        if (epoch % 50 ==0):\n",
    "            checpoint_name = \"checkpoint\" + str(epoch)\n",
    "            save_checkpoint(model, checpoint_name)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b84d99",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56ce3b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 545.124451\n",
      "Epoch: 2 \tTraining Loss: 488.303528\n",
      "Epoch: 3 \tTraining Loss: 527.589539\n",
      "Epoch: 4 \tTraining Loss: 496.061768\n",
      "Epoch: 5 \tTraining Loss: 469.515747\n",
      "Epoch: 6 \tTraining Loss: 478.621277\n",
      "Epoch: 7 \tTraining Loss: 468.878448\n",
      "Epoch: 8 \tTraining Loss: 555.746826\n",
      "Epoch: 9 \tTraining Loss: 494.285095\n",
      "Epoch: 10 \tTraining Loss: 536.043945\n"
     ]
    }
   ],
   "source": [
    "train(model, n_epochs = 10)\n",
    "neptune.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f618c",
   "metadata": {},
   "source": [
    "### function to print images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6eefbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image(image, model, correct_image, neptune_upload = False):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    ax1.imshow(np.transpose(image.numpy(), (1, 2, 0)).astype('uint8'))\n",
    "    ax2.imshow(np.transpose(correct_image.numpy(), (1, 2, 0)).astype('uint8'))\n",
    "    image = torch.unsqueeze(image,0)\n",
    "    image = image.clone().detach().float()\n",
    "    image = image.to(device)\n",
    "    output = model(image)\n",
    "    output = torch.squeeze(output,0)\n",
    "    if device.type == 'cuda':\n",
    "        output = torch.Tensor.cpu(output).clone().detach().numpy()\n",
    "    else:\n",
    "        output = output.clone().detach().numpy()\n",
    "        \n",
    "\n",
    "    ax3.imshow(np.transpose(output, (1, 2, 0)).astype('uint8'))\n",
    "    if neptune_upload:\n",
    "        run['Test_figures'].upload(fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "645c6cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0715077",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24416/3874640845.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print_image(images[0], model = model2, correct_image = images2[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorrect_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneptune_upload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'print_image' is not defined"
     ]
    }
   ],
   "source": [
    "#Test a Model\n",
    "model.eval()\n",
    "\n",
    "images, images2 = dataiter.next()\n",
    "#print_image(images[0], model = model2, correct_image = images2[0])\n",
    "print_image(images[0], model = model, correct_image = images2[0], neptune_upload = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "636aae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model as a artifact\n",
    "def save_checkpoint(model, checkpoint_name):\n",
    "    checkpoint_name_ext = checkpoint_name + \".pt\"\n",
    "    checkpoints = os.listdir(\"Checkpoints\")\n",
    "    path = os.path.join(\"Checkpoints\", checkpoint_name_ext)\n",
    "    try_number = 0\n",
    "    while (os.path.exists(path)):\n",
    "        try_number += 1\n",
    "        checkpoint_name_ext = checkpoint_name + \"_\" + str(try_number) + \".pt\"\n",
    "        path = os.path.join(\"Checkpoints\", checkpoint_name_ext)\n",
    "    torch.save(model, path)\n",
    "    neptune_checkpoint_path = 'model_checkpoints/' + checkpoint_name + \"_\" + str(try_number)\n",
    "    run[neptune_checkpoint_path].upload(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b1a76d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(model,\"size_50_smaller decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "259de4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"Checkpoints/size_50_spohcs_300.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517b0cc4",
   "metadata": {},
   "source": [
    "### Stop the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "58ada837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 1 operations synced, thanks for waiting!\n"
     ]
    }
   ],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c71873",
   "metadata": {},
   "source": [
    "## check speed of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fbf859f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9675dc62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 333.655579\n",
      "Epoch: 2 \tTraining Loss: 434.678711\n"
     ]
    }
   ],
   "source": [
    "%lprun -f train train(model, n_epochs = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "neptune": {
   "notebookId": "9b2d4ae3-0121-433b-b63a-42c0c389e75b",
   "projectVersion": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
